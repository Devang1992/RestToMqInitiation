public ConcurrentMessageListenerContainer<String, String> listenerContainer(
            ConsumerFactory<String, String> consumerFactory) {

        ContainerProperties containerProps = new ContainerProperties("orders-topic");

        containerProps.setMessageListener((MessageListener<String, String>) record -> {
            Header header = record.headers().lastHeader("status");
            String status = (header != null)
                ? new String(header.value(), StandardCharsets.UTF_8)
                : "unknown";

            if ("completed".equalsIgnoreCase(status)) {
                System.out.println("‚úÖ Processed: " + record.value());
            } else {
                System.out.println("‚ùå Skipped (status = " + status + "): " + record.value());
            }
        });

        return new ConcurrentMessageListenerContainer<>(consumerFactory, containerProps);
    }

docker exec -it kafka kafka-console-producer.sh \
  --topic user-events \
  --bootstrap-server localhost:9092 \
  --property "parse.headers=true"

# Then type this and press Enter:
userId:12345	Hello World with header

package com.example.service;

import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class KafkaConsumerService {

    @KafkaListener(topics = "user-events", groupId = "my-consumer-group")
    public void consumeUserEvents(String message) {
        System.out.println("Received user event: " + message);
        // Process the message here
    }

    @KafkaListener(topics = "order-events", groupId = "my-consumer-group")
    public void consumeOrderEvents(String message) {
        System.out.println("Received order event: " + message);
        // Process the message here
    }

    @KafkaListener(topics = "notifications", groupId = "my-consumer-group")
    public void consumeNotifications(String message) {
        System.out.println("Received notification: " + message);
        // Process the message here
    }
}

package com.example.service;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class KafkaProducerService {

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
        System.out.println("Message sent to topic " + topic + ": " + message);
    }

    public void sendMessageWithKey(String topic, String key, String message) {
        kafkaTemplate.send(topic, key, message);
        System.out.println("Message sent to topic " + topic + " with key " + key + ": " + message);
    }
}

# application.yml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: my-consumer-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    admin:
      properties:
        bootstrap.servers: localhost:9092

# Optional: Enable Kafka health check
management:
  health:
    kafka:
      enabled: true

# Create topics using Docker exec
docker exec kafka kafka-topics.sh --create --topic user-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

docker exec kafka kafka-topics.sh --create --topic order-events --bootstrap-server localhost:9092 --partitions 2 --replication-factor 1

docker exec kafka kafka-topics.sh --create --topic notifications --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# List all topics
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# Describe a topic
docker exec kafka kafka-topics.sh --describe --topic user-events --bootstrap-server localhost:9092

# Test producer from command line
docker exec -it kafka kafka-console-producer.sh --topic user-events --bootstrap-server localhost:9092

# Test consumer from command line
docker exec -it kafka kafka-console-consumer.sh --topic user-events --from-beginning --bootstrap-server localhost:9092



# Create a network for Kafka
docker network create kafka-network

# Run Kafka container
docker run -d \
  --name kafka \
  --network kafka-network \
  -p 9092:9092 \
  -e KAFKA_CFG_NODE_ID=0 \
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094 \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,EXTERNAL://localhost:9094 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093 \
  -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true \
  -e ALLOW_PLAINTEXT_LISTENER=yes \
  registry.td.com/td/vendor/bitnami/kafka:3.4.0

# Check if it's running
docker ps

# View logs
docker logs kafka


Run the following command once to initialize the KRaft metadata:

bash
Copy
Edit
docker run --rm \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghij1234567890 \
  bitnami/kafka:3.4.0 \
  kafka-storage.sh format --cluster-id abcdefghij1234567890 --ignore-formatted
Explanation:

This tells Kafka to prepare its internal metadata storage (no ZooKeeper involved).

--ignore-formatted avoids error if you rerun it by mistake.

üîÅ Then: Start Your Kafka Container Again
bash
Copy
Edit
docker run --name kafka-kraft \
  -e ALLOW_PLAINTEXT_LISTENER=yes \
  -e KAFKA_CFG_PROCESS_ROLES=broker,controller \
  -e KAFKA_CFG_NODE_ID=1 \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghij1234567890 \
  -p 9092:9092 -p 9093:9093 \
  bitnami/kafka:3.4.0
You should now see logs indicating successful broker startup.

üß™ Bonus: Test That It‚Äôs Running
bash
Copy
Edit
docker exec -it kafka-kraft \
  kafka-topics.sh --bootstrap-server localhost:9092 --list
If this lists no topics (but runs), you're good.

If it's still exiting:

Run this: docker logs kafka-kraft | tail -n 50

Share that here so I can help debug exactly where it's failing.

You're almost there ‚Äî we just need this one-time setup right.


docker run -d --name kafka-kraft \
  -e KAFKA_CFG_PROCESS_ROLES=broker,controller \
  -e KAFKA_CFG_NODE_ID=1 \



  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka-kraft:9093 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghij1234567890 \
  -p 9092:9092 \
  bitnami/kafka:3.4.0


docker exec -it kafka-kraft kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --topic test-topic --partitions 1 --replication-factor 1


docker run -d --name kafka-kraft \
  -e KAFKA_CFG_PROCESS_ROLES=broker,controller \
  -e KAFKA_CFG_NODE_ID=1 \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghij1234567890 \
  -p 9092:9092 \
  bitnami/kafka:latest


‚úÖ Here's how to run Kafka + Zookeeper locally without Docker Compose:
Since you already have the bitnami/kafka image, let‚Äôs go step-by-step:

üîπ 1. Pull & Run Zookeeper
If you haven‚Äôt pulled it:

bash
Copy
Edit
docker pull bitnami/zookeeper:latest
Run Zookeeper:

bash
Copy
Edit
docker run -d --name zookeeper \
  -e ALLOW_ANONYMOUS_LOGIN=yes \
  -p 2181:2181 \
  bitnami/zookeeper:latest
üîπ 2. Run Kafka and Link it to Zookeeper
Assuming you've already pulled bitnami/kafka:

bash
Copy
Edit
docker run -d --name kafka \
  --link zookeeper:zookeeper \
  -e KAFKA_BROKER_ID=1 \
  -e KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092 \
  -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e ALLOW_PLAINTEXT_LISTENER=yes \
  -p 9092:9092 \
  bitnami/kafka:latest
‚úÖ Now Kafka should be running
Kafka is now listening on port 9092

Zookeeper is running on port 2181

Your Spring Boot app can connect to localhost:9092

üîç Check Containers:
bash
Copy
Edit
docker ps
üß™ Test Kafka (Optional)
Produce a test message:

bash
Copy
Edit
docker exec -it kafka kafka-console-producer.sh \
  --broker-list localhost:9092 --topic test-topic
Consume it:

bash
Copy
Edit
docker exec -it kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic test-topic --from-beginning
