Kafka ItemReader Config
java
Copy
Edit
@Configuration
public class KafkaBatchConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public KafkaItemReader<String, String> kafkaItemReader() {
        KafkaItemReader<String, String> reader = new KafkaItemReaderBuilder<String, String>()
                .partitions(0)  // or .partitions(0, 1, ...) for multiple
                .consumerProperties(Map.of(
                        ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers,
                        ConsumerConfig.GROUP_ID_CONFIG, "batch-consumer-group",
                        ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest",
                        ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class,
                        ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class
                ))
                .name("kafka-item-reader")
                .topic("your-topic-name")
                .build();

        return reader;
    }
}
✅ 4. Spring Batch Job & Step
java
Copy
Edit
@Configuration
public class BatchJobConfig {

    @Bean
    public Step kafkaStep(StepBuilderFactory stepBuilderFactory,
                          KafkaItemReader<String, String> kafkaItemReader) {
        return stepBuilderFactory.get("kafkaStep")
                .<String, String>chunk(10)
                .reader(kafkaItemReader)
                .writer(items -> {
                    for (String item : items) {
                        System.out.println("Processed message: " + item);
                    }
                })
                .build();
    }

    @Bean
    public Job kafkaBatchJob(JobBuilderFactory jobBuilderFactory, Step kafkaStep) {
        return jobBuilderFactory.get("kafkaBatchJob")
                .start(kafkaStep)
                .build();
    }
}
✅ 5. Trigger from Controller
java
Copy
Edit
@RestController
@RequestMapping("/batch")
public class BatchController {

    private final JobLauncher jobLauncher;
    private final Job kafkaBatchJob;

    public BatchController(JobLauncher jobLauncher, @Qualifier("kafkaBatchJob") Job kafkaBatchJob) {
        this.jobLauncher = jobLauncher;
        this.kafkaBatchJob = kafkaBatchJob;
    }

    @GetMapping("/run")
    public ResponseEntity<String> runKafkaJob() {
        try {
            JobParameters jobParameters = new JobParametersBuilder()
                    .addLong("time", System.currentTimeMillis())
                    .toJobParameters();

            jobLauncher.run(kafkaBatchJob, jobParameters);

            return ResponseEntity.ok("Kafka batch job started");
        } catch (Exception e) {
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body("Error: " + e.getMessage());
        }
    }
}

----------------------------------------

application.yml
yaml
Copy
Edit
app:
  kafka:
    topic: my-topic
    group-id: batch-consumer-group

spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        spring.json.trusted.packages: "*"

  batch:
    job:
      enabled: false
✅ 2. MyEvent POJO (Value)
java
Copy
Edit
@Data
@NoArgsConstructor
@AllArgsConstructor
public class MyEvent {
    private String id;
    private String name;
    private String timestamp;
}
✅ 3. Kafka Properties Config Class
java
Copy
Edit
@Component
@ConfigurationProperties(prefix = "app.kafka")
@Data
public class KafkaBatchProperties {
    private String topic;
    private String groupId;
}
✅ 4. KafkaItemReader Config (Deserialize JSON → POJO)
java
Copy
Edit
@Configuration
public class KafkaBatchReaderConfig {

    @Autowired
    private KafkaBatchProperties props;

    @Autowired
    private KafkaProperties kafkaProperties;

    @Bean
    public KafkaItemReader<String, MyEvent> kafkaItemReader() {
        Map<String, Object> consumerProps = kafkaProperties.buildConsumerProperties(props.getGroupId());
        consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        consumerProps.put(JsonDeserializer.TRUSTED_PACKAGES, "*");

        return new KafkaItemReaderBuilder<String, MyEvent>()
                .name("kafka-item-reader")
                .topic(props.getTopic())
                .partitions(0) // You can extend to multiple partitions
                .consumerProperties(consumerProps)
                .keyDeserializer(new StringDeserializer())
                .valueDeserializer(new JsonDeserializer<>(MyEvent.class, false))
                .build();
    }
}
✅ 5. Spring Batch Job Config
java
Copy
Edit
@Configuration
public class KafkaBatchJobConfig {

    @Bean
    public Step kafkaStep(StepBuilderFactory stepBuilderFactory,
                          KafkaItemReader<String, MyEvent> reader) {
        return stepBuilderFactory.get("kafkaStep")
                .<MyEvent, MyEvent>chunk(5)
                .reader(reader)
                .writer(items -> {
                    for (MyEvent event : items) {
                        System.out.println("Processed event: " + event);
                    }
                })
                .build();
    }

    @Bean
    public Job kafkaBatchJob(JobBuilderFactory jobBuilderFactory, Step kafkaStep) {
        return jobBuilderFactory.get("kafkaBatchJob")
                .start(kafkaStep)
                .build();
    }
}
✅ 6. Trigger Job from Controller
java
Copy
Edit
@RestController
@RequestMapping("/batch")
public class KafkaBatchJobController {

    private final JobLauncher jobLauncher;
    private final Job kafkaBatchJob;

    public KafkaBatchJobController(JobLauncher jobLauncher, @Qualifier("kafkaBatchJob") Job kafkaBatchJob) {
        this.jobLauncher = jobLauncher;
        this.kafkaBatchJob = kafkaBatchJob;
    }

    @GetMapping("/run")
    public ResponseEntity<String> runJob() {
        try {
            JobParameters jobParameters = new JobParametersBuilder()
                    .addLong("time", System.currentTimeMillis())
                    .toJobParameters();

            jobLauncher.run(kafkaBatchJob, jobParameters);
            return ResponseEntity.ok("Batch job triggered.");
        } catch (Exception e) {
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body("Batch job failed: " + e.getMessage());
        }
    }
}
✅ Summary

-------------------------------------------------------------------------



KafkaAdminConfig.java
java
Copy
Edit
@Configuration
public class KafkaAdminConfig {
    @Bean
    public AdminClient adminClient(KafkaProperties kafkaProperties) {
        return AdminClient.create(kafkaProperties.buildAdminProperties());
    }

    public List<Integer> getPartitions(String topic, AdminClient adminClient) {
        try {
            var desc = adminClient.describeTopics(List.of(topic))
                .values().get(topic).get();
            return desc.partitions().stream()
                       .map(p -> p.partition()).toList();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
}
5. KafkaJsonReaderConfig.java
java
Copy
Edit
@Configuration
public class KafkaJsonReaderConfig {

    @Autowired KafkaBatchProperties props;
    @Autowired KafkaProperties kafkaProperties;
    @Autowired AdminClient adminClient;
    @Autowired KafkaAdminConfig kafkaAdminConfig;

    @Bean
    public KafkaItemReader<String, JsonNode> reader() {
        var partitions = kafkaAdminConfig.getPartitions(props.getTopic(), adminClient);
        var map = kafkaProperties.buildConsumerProperties(props.getGroupId(), null);
        map.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        map.put(JsonDeserializer.TRUSTED_PACKAGES, "*");

        Properties consumerProps = new Properties();
        map.forEach(consumerProps::put);

        return new KafkaItemReaderBuilder<String, JsonNode>()
                .name("kafka-json-reader")
                .topic(props.getTopic())
                .partitions(partitions.stream().mapToInt(i -> i).toArray())
                .consumerProperties(consumerProps)
                .keyDeserializer(new StringDeserializer())
                .valueDeserializer(new JsonDeserializer<>(JsonNode.class, false))
                .build();
    }
}
6. KafkaBatchJobConfig.java
java
Copy
Edit
@Configuration
public class KafkaBatchJobConfig {

    @Bean
    public Job kafkaJob(JobRepository jr, Step kafkaStep) {
        return new JobBuilder("kafka-job", jr).start(kafkaStep).build();
    }

    @Bean
    public Step kafkaStep(JobRepository jr, PlatformTransactionManager tx, 
                          KafkaItemReader<String, JsonNode> reader) {
        return new StepBuilder("kafka-step", jr)
            .<JsonNode, JsonNode>chunk(ChunkOptions.options().itemCount(10))
            .reader(reader)
            .writer(items -> items.forEach(j -> log.info("Key: {}, Value: {}", 
                                 j.getHeaders().get("key"), j.toString())))
            .transactionManager(tx)
            .build();
    }
}
7. BatchController.java
java
Copy
Edit
@RestController
@RequestMapping("/batch")
public class BatchController {
    @Autowired JobLauncher jobLauncher;
    @Autowired @Qualifier("kafkaJob") Job job;

    @GetMapping("/run")
    public ResponseEntity<String> run() throws Exception {
        var params = new JobParametersBuilder()
                .addLong("time", System.currentTimeMillis()).toJobParameters();
        jobLauncher.run(job, params);
        return ResponseEntity.ok("Job launched");
    }
}
